{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChJazhiel/VAE_NBody/blob/main/VAE_Halo_Finder_Isidro_24_Abril_2nd_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdH7ItOgFu_q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import skimage.measure\n",
        "import skimage.io\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "tf.config.list_physical_devices('GPU')\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "tf.test.is_built_with_cuda()\n",
        "\n",
        "#tf.debugging.set_log_device_placement(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7H73PCV7OQT"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/ChJazhiel/VAE_NBody.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8kKFEOtFx6l"
      },
      "outputs": [],
      "source": [
        "# root_dir = \"/home/isidro/Documents/github/\"\n",
        "# /content/VAE_NBody/Projections_axis_off/D18_x_axis_off_Projection_x_density_density.png\n",
        "image_dir = \"/content/VAE_NBody/Projections_axis_off\"\n",
        "images = [os.path.join(image_dir, image) for image in os.listdir(image_dir)]\n",
        "images[:2]\n",
        "\n",
        "\n",
        "image_halos_dir = \"/content/VAE_NBody/HALOS_Axis_off/Axis_off\"\n",
        "images_halos = [os.path.join(image_halos_dir, image) for image in os.listdir(image_halos_dir)]\n",
        "images_halos[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5n3i3l06ufo"
      },
      "outputs": [],
      "source": [
        " len(images_halos), type(images_halos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3igFshZFPXt"
      },
      "outputs": [],
      "source": [
        "shuffle_idx = np.random.permutation(len(images))\n",
        "shuffle_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXN3eEusGa0r"
      },
      "outputs": [],
      "source": [
        "images = [images[idx] for idx in shuffle_idx]\n",
        "images_halos = [images_halos[idx] for idx in shuffle_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQYTSe94F_af"
      },
      "outputs": [],
      "source": [
        "# preprocess\n",
        "image_size = 256\n",
        "\n",
        "## tf.io is an api for image processing\n",
        "\n",
        "\n",
        "\n",
        "#TensorFlow I/O is a collection of file systems and file formats that are not available in TensorFlow's built-in\n",
        "#support.\n",
        "\n",
        "#It provides useful extra Dataset, streaming, and file system extensions, and is maintained by TensorFlow SIG-IO.\n",
        "\n",
        "#### add a tf.crop in order to resize and add the 3 color channels\n",
        "\n",
        "\n",
        "def preprocess(image):\n",
        "    image = skimage.io.imread(image)\n",
        "    image = cv2.resize(image, (image_size, image_size), interpolation=cv2.INTER_CUBIC)\n",
        "    image = np.reshape(image, (image_size, image_size, 4))\n",
        "    # image = tf.io.decode_jpeg(image)\n",
        "    # #image = tf.cast(image, tf.float32)\n",
        "    # image = tf.image.resize(image, (image_size, image_size))\n",
        "    image = image / 255.0\n",
        "    # # image = tf.image.random_crop(image,  size=[256,256,4])\n",
        "    # image = tf.reshape(image, shape = (image_size, image_size, 4,))\n",
        "\n",
        "\n",
        "    ## add random rotation\n",
        "    image = tf.image.rot90(image, k=3, name=None)\n",
        "    image = image[:,:,:3]\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1Q4C4cTC1Lv"
      },
      "outputs": [],
      "source": [
        "training_dataset = [preprocess(image) for image in images]\n",
        "training_dataset_halos = [preprocess(image) for image in images_halos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6HuZvQ2C8Rv"
      },
      "outputs": [],
      "source": [
        "np.shape(training_dataset), np.shape(training_dataset_halos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k19ve0MDIk-d"
      },
      "outputs": [],
      "source": [
        "noisy_training_dataset = training_dataset + 0.1*np.random.rand(78,256,256,3)\n",
        "noisy_training_dataset_halos = training_dataset_halos + 0.1*np.random.rand(78,256,256,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slkOO4bUJO68"
      },
      "outputs": [],
      "source": [
        "#np.shape(training_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXg_prtHKYN4"
      },
      "outputs": [],
      "source": [
        "training_dataset = np.concatenate((training_dataset, noisy_training_dataset), axis=0)\n",
        "training_dataset_halos = np.concatenate((training_dataset_halos, noisy_training_dataset_halos), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kprcq8-LQM1G"
      },
      "outputs": [],
      "source": [
        "#training_dataset_halos = np.concatenate((training_dataset_halos, noisy_training_dataset_halos), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3zYxIMxN8nf"
      },
      "outputs": [],
      "source": [
        "np.shape(training_dataset), np.shape(training_dataset_halos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LAG2lOHGGkl"
      },
      "outputs": [],
      "source": [
        "# visualize some of them\n",
        "fig, axes = plt.subplots(5,5, figsize = (14,14))\n",
        "# training_dataset[:25]\n",
        "\n",
        "idx = 0\n",
        "# for img in sample:\n",
        "  # img = img[0, :, :, :]\n",
        "for row in range(5):\n",
        "    for column in range(5):\n",
        "        axes[row, column].imshow(noisy_training_dataset_halos[idx][:, :,])\n",
        "        idx += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21bVvF8rGKw9"
      },
      "outputs": [],
      "source": [
        "## Necessary imports\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Dense, Conv2D, Conv2DTranspose, Input, Flatten, BatchNormalization, Lambda, Reshape, Activation\n",
        "from keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJaegIBtLmkW"
      },
      "outputs": [],
      "source": [
        "# np.shape(training_dataset)\n",
        "training_dataset = np.reshape(training_dataset, (len(training_dataset),1,image_size,image_size,3))\n",
        "training_dataset_halos = np.reshape(training_dataset_halos, (len(training_dataset),1,image_size,image_size,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byAx-BtQduo0"
      },
      "outputs": [],
      "source": [
        "latent_dim = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHNMi4DvGe30"
      },
      "outputs": [],
      "source": [
        "# Define the encoder\n",
        "encoder_input = keras.Input(shape=(1, image_size, image_size, 3))\n",
        "x = layers.Conv2D(64, (3,3), activation=\"relu\", strides=2, padding=\"same\")(encoder_input)\n",
        "x = layers.Conv2D(128, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(256, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2D(512, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(100, activation=\"relu\")(x)\n",
        "x = layers.Dense(100, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot4k7W6oHRDV"
      },
      "outputs": [],
      "source": [
        "# Reparameterization trick to sample from the latent space\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim), mean=0., stddev=1.0)\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
        "\n",
        "encoder = keras.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x3qBBmIHuzd"
      },
      "outputs": [],
      "source": [
        "# Define the decoder\n",
        "latent_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(100, activation=\"relu\")(latent_input)\n",
        "x = layers.Dense(100, activation=\"relu\")(x)\n",
        "x = layers.Dense(32 * 32 * image_size, activation=\"relu\")(x)\n",
        "x = layers.Reshape((32, 32, image_size))(x)\n",
        "x = layers.Conv2DTranspose(256, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(128, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(64, (3,3), activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_output = layers.Conv2DTranspose(3, (3,3), activation=\"linear\", padding=\"same\")(x)\n",
        "\n",
        "decoder = keras.Model(latent_input, decoder_output, name=\"decoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soez1UgJJzwJ"
      },
      "outputs": [],
      "source": [
        "# Define the VAE as a whole\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                keras.losses.mean_squared_error(data, reconstruction)\n",
        "            )\n",
        "            kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        return {\n",
        "            \"loss\": total_loss,\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "        }\n",
        "\n",
        "# Create the VAE\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam(0.0001, 0.9, 0.999))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifjH5sTLe5Z3"
      },
      "outputs": [],
      "source": [
        "vae.encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDgntr1OhKse"
      },
      "outputs": [],
      "source": [
        "vae.decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fFSfvbYJ0P0"
      },
      "outputs": [],
      "source": [
        "#  vae.fit(x=training_dataset, y=training_dataset_halos, epochs=10, batch_size=8)\n",
        "history = vae.fit(x=training_dataset, y=training_dataset_halos, epochs=70, batch_size=12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tES-qN5qVX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yp3UnaORWS3"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"reconstruction_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2WyCYJ68sfg"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"kl_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjExYnXNMes6"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"reconstruction_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj0tOfbIKVaX"
      },
      "outputs": [],
      "source": [
        "random_vector_1 = tf.random.normal(shape = (64, latent_dim,))\n",
        "random_vector_2 = tf.random.normal(shape = (64, latent_dim,))\n",
        "\n",
        "\n",
        "generated_images_1 = vae.decoder.predict(random_vector_1)\n",
        "generated_images_2 = vae.decoder.predict(random_vector_2)\n",
        "len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8uPa0zrU-eJ"
      },
      "outputs": [],
      "source": [
        "np.shape(random_vector_1), type(random_vector_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ox0inAaRvQx"
      },
      "outputs": [],
      "source": [
        "np.shape(generated_images_2), type(generated_images_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJn3F744LN1Q"
      },
      "outputs": [],
      "source": [
        "# Plot the generated images\n",
        "n = len(generated_images_1)\n",
        "rows = 8\n",
        "cols = n // rows\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(n):\n",
        "    #plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(generated_images_1[i])\n",
        "    #plt.imshow(generated_images_2[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# visualize some of them\n",
        "#fig, axes = plt.subplots(5,5, figsize = (14,14))\n",
        "# training_dataset[:25]\n",
        "\n",
        "#idx = 0\n",
        "# for img in sample:\n",
        "  # img = img[0, :, :, :]\n",
        "#for row in range(5):\n",
        " #   for column in range(5):\n",
        " #       axes[row, column].imshow(generated_images_1[i])\n",
        "        #axes[row, column].imshow(generated_images_2)\n",
        "        #idx += 1\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYM5qs3gMBb9"
      },
      "outputs": [],
      "source": [
        "# Plot the generated images\n",
        "n = len(generated_images_1)\n",
        "rows = 8\n",
        "cols = n // rows\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(n):\n",
        "    #plt.subplot(rows, cols, i + 1)\n",
        "    #plt.imshow(generated_images_1[i])\n",
        "    plt.imshow(generated_images_2[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcACImoyf137"
      },
      "outputs": [],
      "source": [
        "###Graficar media y varianza\n",
        "\n",
        "## cambiar tamaño del filtro a 3x3 o 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwo1-UjkAMgB"
      },
      "outputs": [],
      "source": [
        "tf.shape(z_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akMebBuDAPIb"
      },
      "outputs": [],
      "source": [
        "print(z_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXWwCOVpAqET"
      },
      "outputs": [],
      "source": [
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF8H3E9zBMb2"
      },
      "outputs": [],
      "source": [
        "latent_dim = latent_dim\n",
        "\n",
        "random_vector_1 = tf.random.normal(shape = (8, latent_dim,))\n",
        "random_vector_2 = tf.random.normal(shape = (8, latent_dim,))\n",
        "\n",
        "\n",
        "generated_images_1 = vae.decoder.predict(random_vector_1)\n",
        "generated_images_2 = vae.decoder.predict(random_vector_2)\n",
        "\n",
        "encoded = vae.encoder.predict(training_dataset)\n",
        "\n",
        "z_mean_values = encoded[0]  # Extract z_mean values\n",
        "z_log_var_values = encoded[1]  # Extract z_log_var values\n",
        "\n",
        "# Now you can plot z_mean and z_log_var in a 2D plot\n",
        "plt.scatter(z_mean_values[:, 0], z_mean_values[:, 1], c='r', label='z_mean')\n",
        "plt.scatter(z_log_var_values[:, 0], z_log_var_values[:, 1], c='b', label='z_log_var')\n",
        "plt.legend()\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('Latent Space Visualization')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A85Hl2wcQ4iG"
      },
      "source": [
        "## Using an image without halos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfuyNJc5Q7Lx"
      },
      "outputs": [],
      "source": [
        "file = '/content/VAE_NBody/Projections_axis_off/D18_x_axis_off_Projection_x_density_density.png'\n",
        "test_image = preprocess(file)\n",
        "test_image = np.reshape(test_image, (1, image_size, image_size, 3))\n",
        "np.shape(test_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMSMAYZJRJiD"
      },
      "outputs": [],
      "source": [
        "n = len(test_image)\n",
        "rows = 8\n",
        "cols = n // rows\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(n):\n",
        "    #plt.subplot(rows, cols, i + 1)\n",
        "    #plt.imshow(generated_images_1[i])\n",
        "    plt.imshow(test_image[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-3WXWXnSg4T"
      },
      "outputs": [],
      "source": [
        "test_pred = encoder.predict(test_image)\n",
        "np.shape(test_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH3cN3HbVT6F"
      },
      "outputs": [],
      "source": [
        "# test_tensor =  tf.convert_to_tensor(test_pred)\n",
        "# np.shape(test_tensor), type(test_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNkq6IaEUMm7"
      },
      "outputs": [],
      "source": [
        "test_pred2 = decoder.predict(test_pred[2])\n",
        "np.shape(test_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIUyvwj8UxN6"
      },
      "outputs": [],
      "source": [
        "n = len(test_pred2)\n",
        "rows = 8\n",
        "cols = n // rows\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "#for i in range(n):\n",
        "    #plt.imshow(generated_images_1[i])\n",
        "plt.imshow(test_pred2[0,:,:,:])\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5z-pxnTWSf_"
      },
      "outputs": [],
      "source": [
        "# prompt: from the above code try to generate a histogram of the tensor recently plotted as image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Extract the tensor from the last plot\n",
        "tensor = test_pred2[0,:,:,0]\n",
        "\n",
        "# Flatten the tensor\n",
        "flat_tensor = tensor.flatten()\n",
        "\n",
        "# Create a histogram with 20 bins\n",
        "plt.hist(flat_tensor, bins=100)\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title(\"Histogram of Tensor Values\")\n",
        "plt.xlabel(\"Tensor Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q1SSzIifDJ_"
      },
      "outputs": [],
      "source": [
        "# prompt: from the code above, generate a histogram of the original image plotted\n",
        "\n",
        "# Extract the tensor from the original image\n",
        "tensor = test_image[0,:,:,0]\n",
        "\n",
        "# Flatten the tensor\n",
        "flat_tensor = tensor.flatten()\n",
        "\n",
        "# Create a histogram with 20 bins\n",
        "plt.hist(flat_tensor, bins=100)\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title(\"Histogram of Original Image Tensor Values\")\n",
        "plt.xlabel(\"Tensor Values\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FIPLHHZSV5T"
      },
      "outputs": [],
      "source": [
        "# prompt: get the fourier transform of the previous image tensors and plot them\n",
        "\n",
        "# Extract the tensor from the last plot\n",
        "tensor = test_pred2[0,:,:,0]\n",
        "\n",
        "# Flatten the tensor\n",
        "flat_tensor = tensor.flatten()\n",
        "\n",
        "# Compute the Fourier transform\n",
        "fft_values = np.fft.fft(flat_tensor)\n",
        "\n",
        "# Shift the zero frequency component to the center of the spectrum\n",
        "fft_shifted = np.fft.fftshift(fft_values)\n",
        "\n",
        "# Create a frequency axis\n",
        "frequency_axis = np.linspace(-len(flat_tensor) // 2, len(flat_tensor) // 2 - 1, len(flat_tensor))\n",
        "\n",
        "# Plot the magnitude of the Fourier transform\n",
        "plt.plot(frequency_axis, np.abs(fft_shifted))\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Magnitude\")\n",
        "plt.title(\"Magnitude of the Fourier Transform of the Tensor\")\n",
        "plt.show()\n",
        "\n",
        "# Extract the tensor from the original image\n",
        "tensor = test_image[0,:,:,0]\n",
        "\n",
        "# Flatten the tensor\n",
        "flat_tensor = tensor.flatten()\n",
        "\n",
        "# Compute the Fourier transform\n",
        "fft_values = np.fft.fft(flat_tensor)\n",
        "\n",
        "# Shift the zero frequency component to the center of the spectrum\n",
        "fft_shifted = np.fft.fftshift(fft_values)\n",
        "\n",
        "# Create a frequency axis\n",
        "frequency_axis = np.linspace(-len(flat_tensor) // 2, len(flat_tensor) // 2 - 1, len(flat_tensor))\n",
        "\n",
        "# Plot the magnitude of the Fourier transform\n",
        "plt.plot(frequency_axis, np.abs(fft_shifted))\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Magnitude\")\n",
        "plt.title(\"Magnitude of the Fourier Transform of the Original Image Tensor\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EB8QHDumWnoJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}